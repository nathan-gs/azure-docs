---
title: Process vehicle sensor data with Apache Storm on HDInsight | Microsoft Docs
description: Learn how to process vehicle sensor data from Event Hubs using Apache Storm on HDInsight. Add model data from Azure Cosmos DB, and store output to storage.
services: hdinsight,documentdb,notification-hubs
documentationcenter: ''
author: Blackmist
manager: jhubbard
editor: cgronlun

ms.assetid: 78980635-8bef-4c33-96c3-fae50e932e31
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: java
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/03/2017
ms.author: larryfr

---
# Process vehicle sensor data from Azure Event Hubs using Apache Storm on HDInsight

Learn how to process vehicle sensor data from Azure Event Hubs using Apache Storm on HDInsight. This example reads sensor data from Azure Event Hubs, enriches the data by referencing data stored in Azure Cosmos DB. The data is stored into Azure Storage using the Hadoop File System (HDFS).

![HDInsight and the Internet of Things (IoT) architecture diagram](./media/hdinsight-storm-iot-eventhub-documentdb/iot.png)

## Overview

Adding sensors to vehicles allows you to predict equipment problems based on historical data trends. It also allows you to make improvements to future versions based on usage pattern analysis. You must be able to quickly and efficiently load the data from all vehicles into Hadoop before MapReduce processing can occur. Additionally, you may wish to do analysis for critical failure paths (engine temperature, brakes, etc.) in real time.

Azure Event Hubs is built to handle the massive volume of data generated by sensors. Apache Storm can be used to load and process the data before storing it into HDFS.

## Solution

Telemetry data for engine temperature, ambient temperature, and vehicle speed is recorded by sensors. Data is then sent to Event Hubs along with the car's Vehicle Identification Number (VIN) and a time stamp. From there, a Storm Topology running on an Apache Storm on HDInsight cluster reads the data, processes it, and stores it into HDFS.

During processing, the VIN is used to retrieve model information from Cosmos DB. This data is added to the data stream before it is stored.

The components used in the Storm Topology are:

* **EventHubSpout** - reads data from Azure Event Hubs
* **TypeConversionBolt** - converts the JSON string from Event Hubs into a tuple containing the following sensor data:
    * Engine temperature
    * Ambient temperature
    * Speed
    * VIN
    * Timestamp
* **DataReferencBolt** - looks up the vehicle model from Cosmos DB using the VIN
* **WasbStoreBolt** - stores the data to HDFS (Azure Storage)

The following image is a diagram of this solution:

![storm topology](./media/hdinsight-storm-iot-eventhub-documentdb/iottopology.png)

## Implementation

A complete, automated solution for this scenario is available as part of the [HDInsight-Storm-Examples](https://github.com/hdinsight/hdinsight-storm-examples) repository on GitHub. To use this example, follow the steps in the [IoTExample README.MD](https://github.com/hdinsight/hdinsight-storm-examples/blob/master/IotExample/README.md).

## Next Steps

For more example Storm topologies, see [Example topologies for Storm on HDInsight](hdinsight-storm-example-topology.md).

